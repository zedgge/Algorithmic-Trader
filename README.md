# Intelligent Algorithmic Trading System (Quantitative + ML Framework)

**Author:** [Your Name]  
**Education:** Self-directed study with advanced coursework from MIT and Harvard  
**Technologies:** Python, PyTorch (CUDA), Pandas, NumPy, XGBoost, Joblib, Alpaca API, Yahoo Finance, Vector Databases, Bloomberg API (in progress)

---

## ğŸ“Š Overview

This project documents a **fully self-built quantitative trading and research system** that combines **machine learning, statistical modeling, and automated execution** across multiple markets.  
The system was designed to **analyze, predict, and trade financial instruments autonomously**, while learning continuously from live and historical data.

Over a **four-month live test**, the system achieved a **12.2% ROI with a 56% win rate**, executing trades through the Alpaca API using real market data.  
The application featured **automated trading, portfolio risk management, multi-model signal validation, and adaptive learning loops** â€” all developed independently while completing MIT and Harvard online coursework in quantitative methods, machine learning, and computational systems.

---

## ğŸ§  Continuous Learning and Market Adaptation

Outside of active market sessions, the system entered a **continuous-learning mode**.  
During this time, it processed post-market data, recalculated rolling features, and fine-tuned model parameters based on recent **regime behavior** â€” including volatility shifts, liquidity changes, and sector rotation trends.  
This asynchronous training loop minimized model drift and ensured all predictive components were recalibrated before each market open.  
It also dynamically adjusted signal thresholds and **volatility-based position sizing** to maintain capital efficiency during changing market conditions.

---

## âš™ï¸ System Architecture

The framework was structured into four primary layers for modularity, speed, and control:

### 1. Data Layer
- Live and historical market data from **Yahoo Finance** and **Alpaca**, with partial **Bloomberg API** integration.  
- Normalized multi-market inputs with synchronized timestamps to avoid misalignment between asset classes.  
- Implemented feature generation for momentum, volume pressure, volatility bands, VWAP deviation, and trend correlation.  
- Stored embeddings in **vector databases** for historical condition matching and pattern recall.

### 2. Modeling Layer
- **Temporal Fusion Transformers (TFT)** for multi-horizon forecasting and market regime tracking.  
- **XGBoost** ensemble models for short-term directional prediction and volatility classification.  
- Model persistence and fast recall through **Joblib**.  
- Confidence-weighted ensemble logic that automatically prioritized higher-confidence models based on live volatility and data reliability.  

### 3. Execution Layer
- Integrated directly with **Alpacaâ€™s API** for live order routing and account management.  
- Supported **single-market** or **multi-market execution**, with internal throttling for rate-limited APIs.  
- Conducted pre-trade validation (exposure, margin, spread, liquidity) and post-trade audit logging (execution time, fill quality, latency).  
- Operated in three selectable modes:
  - **Autonomous trading:** fully automated execution  
  - **Assisted trading:** requires confirmation  
  - **Research/backtesting:** simulation only  

### 4. Risk and Capital Management
- Dynamically adjusted **risk exposure** and **position size** based on rolling volatility and capital utilization.  
- Implemented **drawdown limits**, **exposure caps**, and **auto-shutdown** safeguards.  
- Real-time exposure tracking across correlated instruments to prevent over-leveraging.  
- Time-based halts before major economic events, news releases, or low-liquidity sessions.  

---

## ğŸ“ˆ Machine Learning and Quantitative Methods

- **Framework:** PyTorch with CUDA acceleration.  
- **Training Data:** Combined OHLCV data, technical indicators, sentiment signals, and event-based features.  
- **Models:** Temporal Fusion Transformers (for trend and context learning) and XGBoost (for directional classification).  
- **Metrics:** Sharpe ratio, Sortino ratio, drawdown, profit factor, hit rate, and precision-recall balance.  
- **Adaptive Training:** The system retrained nightly with fresh data to account for market drift, regime changes, and volatility clustering.  

---

## ğŸ’¡ Core Features

- **Continuous Off-Hours Learning:** Automatically retrains and optimizes models during closed-market hours.  
- **Market-Aware Execution:** Trades adapted to session times, liquidity conditions, and volatility spikes.  
- **Multi-Asset Support:** Operated across equities, crypto, and forex.  
- **Dynamic Risk Management:** Volatility-adjusted position sizing and live exposure control.  
- **Capital Efficiency:** Intelligent scaling to prevent drawdown while maintaining exposure to outperforming sectors.  
- **Event Logging:** Full traceability of every model inference, trade decision, and system action.  
- **Alerting System:** News-driven watchlists and predictive movement signals.  
- **Fail-Safe Logic:** Automatic pause on network errors, excessive volatility, or strategy divergence.

---

## ğŸ§© Design Philosophy

1. **Precision:** Every component optimized for sub-millisecond latency during trade routing.  
2. **Resilience:** Failsafe systems and drawdown triggers protect against market shocks.  
3. **Transparency:** Every execution and model decision is auditable.  
4. **Efficiency:** Designed to maximize computational output without additional hardware.  
5. **Modularity:** Each layer can be independently replaced or upgraded.  
6. **Security:** All API keys, data feeds, and user operations encrypted and sandboxed.

---

## ğŸ”’ Why the Full Code Isnâ€™t Public

Due to a **hardware failure**, portions of the original system code and GUI were lost.  
Additionally, parts of the algorithm, data handling, and trading logic are withheld for **security and proprietary reasons**, as they may be used in future redevelopment.  
This repository serves as a **technical reference and design documentation**, with selected snippets and architecture visuals for verification.

---

## ğŸš€ Planned Improvements

The next major iteration will include:

- Completion of **Bloomberg API** integration for higher-quality data.  
- Enhanced **GPU utilization and inference optimization** for large-scale parallel processing.  
- **Cluster-based performance balancing** for distributed trading operations.  
- Improved **large-data throughput** for higher-volume multi-market operation.  
- Microsecond-level **interaction logging** for all system and user actions.  
- Deep optimization for **ultra-low latency** without hardware upgrades.  
- Rebuilt **GUI** â€” faster, fully customizable, and more intuitive.  
- Expanded **security layer** to protect both local and cloud-based operations.

---

## ğŸ¯ Why This Project Matters

This project reflects my practical understanding of how markets behave â€” from intraday liquidity shifts to volatility clustering and regime transitions.  
It demonstrates experience not just in data science, but in **real-world market mechanics**, **execution infrastructure**, and **risk-adjusted capital deployment**.  
It represents the foundation of a future production-level quantitative framework capable of adapting to changing conditions, managing exposure intelligently, and continuously improving through feedback.

---

## ğŸ“¬ Contact

**Email:** [your_email@domain.com]  
**LinkedIn:** [Your LinkedIn Profile]  

---

> *â€œMarkets arenâ€™t random â€” theyâ€™re complex systems driven by liquidity, behavior, and timing.  
> The advantage lies in measuring those dynamics faster and reacting before everyone else.â€*
